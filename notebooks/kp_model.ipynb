{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9938b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3320e5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dsc_time</th>\n",
       "      <th>dsc_bx_gse</th>\n",
       "      <th>dsc_by_gse</th>\n",
       "      <th>dsc_bz_gse</th>\n",
       "      <th>dsc_bx_gsm</th>\n",
       "      <th>dsc_by_gsm</th>\n",
       "      <th>dsc_bz_gsm</th>\n",
       "      <th>wind_bx_gsm</th>\n",
       "      <th>wind_by_gsm</th>\n",
       "      <th>wind_bz_gsm</th>\n",
       "      <th>wind_bx_gse</th>\n",
       "      <th>wind_by_gse</th>\n",
       "      <th>wind_bz_gse</th>\n",
       "      <th>Kp_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.638317e+12</td>\n",
       "      <td>-4.14748</td>\n",
       "      <td>2.57484</td>\n",
       "      <td>5.80215</td>\n",
       "      <td>-4.14748</td>\n",
       "      <td>2.48670</td>\n",
       "      <td>5.84047</td>\n",
       "      <td>0.088021</td>\n",
       "      <td>4.011500</td>\n",
       "      <td>4.443556</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>4.110653</td>\n",
       "      <td>4.351998</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.638317e+12</td>\n",
       "      <td>-4.38719</td>\n",
       "      <td>2.43669</td>\n",
       "      <td>5.85642</td>\n",
       "      <td>-4.38719</td>\n",
       "      <td>2.34778</td>\n",
       "      <td>5.89262</td>\n",
       "      <td>0.743966</td>\n",
       "      <td>4.511123</td>\n",
       "      <td>4.838581</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>4.619002</td>\n",
       "      <td>4.735743</td>\n",
       "      <td>3.999935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.638317e+12</td>\n",
       "      <td>-4.16530</td>\n",
       "      <td>2.82073</td>\n",
       "      <td>5.58057</td>\n",
       "      <td>-4.16530</td>\n",
       "      <td>2.73598</td>\n",
       "      <td>5.62260</td>\n",
       "      <td>1.551022</td>\n",
       "      <td>3.971076</td>\n",
       "      <td>4.476637</td>\n",
       "      <td>1.550803</td>\n",
       "      <td>4.070888</td>\n",
       "      <td>4.386144</td>\n",
       "      <td>3.999870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.638317e+12</td>\n",
       "      <td>-4.40910</td>\n",
       "      <td>3.04584</td>\n",
       "      <td>5.99368</td>\n",
       "      <td>-4.40910</td>\n",
       "      <td>2.95486</td>\n",
       "      <td>6.03905</td>\n",
       "      <td>0.571862</td>\n",
       "      <td>3.344407</td>\n",
       "      <td>5.211400</td>\n",
       "      <td>0.571598</td>\n",
       "      <td>3.460871</td>\n",
       "      <td>5.134824</td>\n",
       "      <td>3.999804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.638317e+12</td>\n",
       "      <td>-4.11849</td>\n",
       "      <td>3.35687</td>\n",
       "      <td>5.77462</td>\n",
       "      <td>-4.11849</td>\n",
       "      <td>3.26920</td>\n",
       "      <td>5.82470</td>\n",
       "      <td>0.985459</td>\n",
       "      <td>3.322290</td>\n",
       "      <td>5.867872</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>3.453475</td>\n",
       "      <td>5.791687</td>\n",
       "      <td>3.999739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      dsc_time  dsc_bx_gse  dsc_by_gse  dsc_bz_gse  dsc_bx_gsm  \\\n",
       "0           0  1.638317e+12    -4.14748     2.57484     5.80215    -4.14748   \n",
       "1           1  1.638317e+12    -4.38719     2.43669     5.85642    -4.38719   \n",
       "2           2  1.638317e+12    -4.16530     2.82073     5.58057    -4.16530   \n",
       "3           3  1.638317e+12    -4.40910     3.04584     5.99368    -4.40910   \n",
       "4           4  1.638317e+12    -4.11849     3.35687     5.77462    -4.11849   \n",
       "\n",
       "   dsc_by_gsm  dsc_bz_gsm  wind_bx_gsm  wind_by_gsm  wind_bz_gsm  wind_bx_gse  \\\n",
       "0     2.48670     5.84047     0.088021     4.011500     4.443556     0.087816   \n",
       "1     2.34778     5.89262     0.743966     4.511123     4.838581     0.743736   \n",
       "2     2.73598     5.62260     1.551022     3.971076     4.476637     1.550803   \n",
       "3     2.95486     6.03905     0.571862     3.344407     5.211400     0.571598   \n",
       "4     3.26920     5.82470     0.985459     3.322290     5.867872     0.985153   \n",
       "\n",
       "   wind_by_gse  wind_bz_gse  Kp_index  \n",
       "0     4.110653     4.351998  4.000000  \n",
       "1     4.619002     4.735743  3.999935  \n",
       "2     4.070888     4.386144  3.999870  \n",
       "3     3.460871     5.134824  3.999804  \n",
       "4     3.453475     5.791687  3.999739  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C://Users/kamel/Downloads/Nasa_Space_Apps_2023/New Folder/Mag.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094513a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_bx_gsm</th>\n",
       "      <th>wind_by_gsm</th>\n",
       "      <th>wind_bz_gsm</th>\n",
       "      <th>wind_bx_gse</th>\n",
       "      <th>wind_by_gse</th>\n",
       "      <th>wind_bz_gse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088021</td>\n",
       "      <td>4.011500</td>\n",
       "      <td>4.443556</td>\n",
       "      <td>0.087816</td>\n",
       "      <td>4.110653</td>\n",
       "      <td>4.351998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743966</td>\n",
       "      <td>4.511123</td>\n",
       "      <td>4.838581</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>4.619002</td>\n",
       "      <td>4.735743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.551022</td>\n",
       "      <td>3.971076</td>\n",
       "      <td>4.476637</td>\n",
       "      <td>1.550803</td>\n",
       "      <td>4.070888</td>\n",
       "      <td>4.386144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571862</td>\n",
       "      <td>3.344407</td>\n",
       "      <td>5.211400</td>\n",
       "      <td>0.571598</td>\n",
       "      <td>3.460871</td>\n",
       "      <td>5.134824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985459</td>\n",
       "      <td>3.322290</td>\n",
       "      <td>5.867872</td>\n",
       "      <td>0.985153</td>\n",
       "      <td>3.453475</td>\n",
       "      <td>5.791687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wind_bx_gsm  wind_by_gsm  wind_bz_gsm  wind_bx_gse  wind_by_gse  \\\n",
       "0     0.088021     4.011500     4.443556     0.087816     4.110653   \n",
       "1     0.743966     4.511123     4.838581     0.743736     4.619002   \n",
       "2     1.551022     3.971076     4.476637     1.550803     4.070888   \n",
       "3     0.571862     3.344407     5.211400     0.571598     3.460871   \n",
       "4     0.985459     3.322290     5.867872     0.985153     3.453475   \n",
       "\n",
       "   wind_bz_gse  \n",
       "0     4.351998  \n",
       "1     4.735743  \n",
       "2     4.386144  \n",
       "3     5.134824  \n",
       "4     5.791687  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 8:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb1f99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.000000\n",
       "1    3.999935\n",
       "2    3.999870\n",
       "3    3.999804\n",
       "4    3.999739\n",
       "Name: Kp_index, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Kp_index'][:900000]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c388ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, testPercentage=0.2):\n",
    "    num_rows = X.shape[0]\n",
    "    num_test = int(num_rows * testPercentage)\n",
    "    X_train, X_test = X[:-num_test], X[-num_test:]\n",
    "    y_train, y_test = y[:-num_test], y[-num_test:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ede17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd417d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_1[0][0]']                \n",
      "                                thPoolingAndCrossAt                                               \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 6, 7                                               \n",
      "                                68),                                                              \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 6, 768)      9447168     ['tf_bert_model[0][0]',          \n",
      " dAttention)                                                      'tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 6, 768)      0           ['multi_head_attention[0][0]',   \n",
      " da)                                                              'tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 6, 768)      1536        ['tf.__operators__.add[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 6, 768)      9447168     ['layer_normalization[0][0]',    \n",
      " eadAttention)                                                    'tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 6, 768)      0           ['multi_head_attention_1[0][0]', \n",
      " mbda)                                                            'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 6, 768)      1536        ['tf.__operators__.add_1[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6, 768)       590592      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 6, 768)      0           ['dense[0][0]',                  \n",
      " mbda)                                                            'layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 6, 768)      1536        ['tf.__operators__.add_2[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4608)         0           ['layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           294976      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 129,268,865\n",
      "Trainable params: 19,786,625\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Define the transformer decoder function\n",
    "def transformer_decoder(input_layer, enc_output, d_model, nhead):\n",
    "    attn_output1 = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)(input_layer, input_layer)\n",
    "    attn_output1 = layers.LayerNormalization(epsilon=1e-6)(attn_output1 + input_layer)\n",
    "    attn_output2 = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)(attn_output1, enc_output)\n",
    "    attn_output2 = layers.LayerNormalization(epsilon=1e-6)(attn_output2 + attn_output1)\n",
    "    ffn_output = layers.Dense(d_model)(attn_output2)\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(ffn_output + attn_output2)\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "bert_encoder = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Make BERT layers non-trainable\n",
    "for layer in bert_encoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "input1 = layers.Input(shape=(6, ), dtype='int32')\n",
    "\n",
    "# BERT layer\n",
    "bert_output = bert_encoder(input1)[0]\n",
    "\n",
    "# Decoder part\n",
    "dec_output = transformer_decoder(bert_output, bert_output, d_model=768, nhead=4)\n",
    "\n",
    "# Fully connected layers\n",
    "x = layers.Flatten()(dec_output)\n",
    "x = layers.Dense(64)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(32)(x)\n",
    "\n",
    "# Output layer for regression\n",
    "output = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae61b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model_history = model.fit(X_train, y_train,\n",
    "                          validation_data=(X_test, y_test),\n",
    "                          batch_size=32,\n",
    "                          epochs=1,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce2a27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('kp_prediction.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
